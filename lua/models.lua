local models = {
	perplexity = "llama-3.1-sonar-large-128k-chat",
	openai = "gpt-4o",
	anthropic = "claude-3-5-sonnet-latest",
	groq = "llama-3.3-70b-versatile",
	ollama = "llama3.3:latest",
}

return models
