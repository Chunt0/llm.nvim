local models = {
	perplexity = "llama-3.1-sonar-large-128k-chat",
	openai = "gpt-4o",
	anthropic = "claude-3-5-sonnet-20240620",
	groq = "llama-3.1-70b-versatile",
	ollama = "llama3.1:70b-instruct-q4_0",
}

return models
